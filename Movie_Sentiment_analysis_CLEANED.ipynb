{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_G5PvJKx7LO",
    "outputId": "7a07478b-25d1-4aea-ed07-fe6bc4f928af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lOpZAQsyKW4",
    "outputId": "12779c78-f622-4f9a-af2d-144a63327521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "#checking for gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557,
     "referenced_widgets": [
      "bc07e364b2dd47368b7c5763686af4f9",
      "01edfe26cf3e4ec6b5672611333bb97c",
      "900f4e69ea8644c99c0295ed73e3d224",
      "1da5baaf4a8e4e6f928dc80f8ca4cbf2",
      "0a6923afb10e4090935771510d3a50f2",
      "0fa469c9e0354e58b07bd459e0b8f6c7",
      "5a7d0b08e9494e9c861aeef46caf1a1c",
      "cc915710d5ee4093b7e7d3aa9bdd86b6",
      "b435a098787c4fa5bc7a3c476cf0be84",
      "35caf79068a948ff804df9b02f9cea59",
      "ccd414785abf475fa03f78cb35cc8ce6",
      "aa59f667aec04669b8be523defc1be22",
      "7a92ab97f871420090244008534076fc",
      "01011691e9ab46698d8b842ea13dea1f",
      "fadf38d296b649a39e7c94fc8f970be6",
      "287abb3ec685444b8273b4ce9e9b4d6d",
      "fc4314f65ccd4e4b9788128c3bd155b3",
      "f138c7f98c654256b69dd0304dbf608c",
      "73de4c7286f64d98be83e26850ffc40e",
      "91918420b0194d779d56990570dcf994",
      "16cb5bfeb11846dd84e0ea123dd32dee",
      "bc13902015804de9bd974c2197c7b5e8",
      "e25f942219874531b18bdf96145e7c55",
      "0266890d884249128d25aea2673090af",
      "6af364756d6744c3b74eeb55b9fe8756",
      "8e50cbab7a844365b0eea9fa8592d4e2",
      "2f0415106eff44fda7d47447954ffde5",
      "aebfb0c52373448ba60e27deebd4a5c2",
      "c6699a7d89994bb5b6687910345f7088",
      "0118ab5c6f0d4bbd9198fd11b5d434b9",
      "7ea27e10a8344dcea614d866b7596641",
      "7649d4026de04f46a26ac8ddc2289892",
      "1de53e26f1574e38a9c3a36302a9b60d",
      "744687a04db84f57945617adc02b903a",
      "9e8d61ae0ba14ba9bd4972c4c62bd6d9",
      "1aebbaf298d2411895105d909f8003b9",
      "bc644aacd43b42349ebf182f499bbb55",
      "bcd3ff6fe176466d8af1070b5a454c64",
      "f6e9f89ae5a5460fa30d8315920c6a0b",
      "757ee00361cf4c3496b3920336dca409",
      "b566c6e0315d4093abc3e1614b35a06c",
      "2e899d7883834ef09f218df27badc16c",
      "2d723be600b54d33b87f561e99e53ec1",
      "9e3d3c3640844694bc5167f99e42dd47",
      "e66f76085eb846f785a5585de34cd344",
      "06d3d5ce827d442d81f7e3a657def94a",
      "3014da62fce746be8650ce5dbffe5bd0",
      "1e55cb33d48a47cb9aa2467146edf119",
      "9560e15a2f5148c1a2d505f157ea9051",
      "b3f18ff3d7e740dc916dfd9d87660264",
      "21309a03ad274578a8dba508f15e69d1",
      "077ff01e8e1e425585eb0bf1da0828b9",
      "30b36de173f34851abb82941871dcc1b",
      "b88d348cff72458d86e086d6bc370f13",
      "c284350936fb475291bf80ab9a9e8af3",
      "680d1ae1700d44d2bf92338873d9a9d4",
      "a39a55c4a0974c309f9f826eb4709afc",
      "5c1acb54173340e0a27236f52db39239",
      "7841960a9c624fa89063df7318fc9727",
      "88eb14da06534e3d867c40452e940dd6",
      "7140e26ed6194fb5a77e6f54ff83e851",
      "1034b0cbd0f24fb284ec11a5366687c3",
      "258291fbaa494a40ac322fade2a38c57",
      "68c91818c4114e04b53a4e0c2fea4776",
      "62b376445f034047919089405495f951",
      "b37871006d86449a8a44295e6d06d99e",
      "debdda67208c43c4be8aa327777cbf81",
      "68d2e8dd62334cdb8b418ed6e31b7d0f",
      "659e1d8888684e0588ade2fb10dadf99",
      "e0e78578794c4830b682a4cb23d3173f",
      "da879bf72f654dc4b3e3a4e714b08da7",
      "1d3ba9aa67d54da29f06907eb7a0e3a9",
      "04816be86d12474aac5d53b108a5e92e",
      "2726ac676d1445f2803f1580e034552b",
      "b3f3910dfa3c4acf8545a4e2575282c8",
      "05ac7472e2de4f33bea4ad9e0c6751bb",
      "5212fe2219da47ffaa3e23909abde243",
      "ee94082cbe9f47f2ba98cadc537889bf",
      "efd6be12b7674bcba6264da862ab0ea1",
      "f030c2b30cba47d3a1e763af4b0aa043",
      "b74a18a6f1f14199a6c639445db332ca",
      "da65c1ad792e4c11883c406ad9d10eb0",
      "039fc4efa9274087b22cb2d369c8f655",
      "29c55616a6c248f0b2e930e9314447a1",
      "a91f07c81f2345549a2c78de55177c6a",
      "389ef82f5a934d9899b0dd2dd8db5797",
      "53f339a06631478a9fdeb521778e97ee",
      "a2b8c460b83b485e8865de5f709904ef",
      "dbce513d953d42768fc7028b54a8d562",
      "cb262a8a9c5a4d628eeac7caec7c485b",
      "31274fcd581348498a160fec41672ae9",
      "56a0136f25a44682a563f70ce47f3326",
      "05bc3b2e20ad4e5498e96f740f5e8fc4",
      "e607ad9b2eea48639d80b7f324bf8232",
      "e067f7009cb549af92d0611b24f343a9",
      "dda1fb466d094d92b207403eb928a4d8",
      "4624f22fbac048cc8414fd9dc76ece65",
      "2b76c5ef4c9647e297d429a39857ab73",
      "bcd5d2feb08a4167bdf1e97eb05cb3c9",
      "818bb765e6cb4934b737dc224764c589",
      "70cada942bb54cd88db5aeccb812909a",
      "eacc607012b4446685048a1e1e4a8ad5",
      "68126c7bd8794eaaac97cd3e1e31165e",
      "3ee44a3f670a44f087697184dfcb5b14",
      "cf516550dfbb4ef4b6020b57aa073a27",
      "ef797d50cc0440ad8b4d930f33569906",
      "0c41e58523d24829869131de0fe11992",
      "df09754a06f44ecbb3fc70a4f5db18bb",
      "7124c136da954ba4a4f9d77a4144889a",
      "26c5312eca1042f29d3d6dd0e7016ab3",
      "b813fc779ab24c6b9273a14ea1a3936d",
      "7f5878d63c224fae9695d066e312bd08",
      "235ceb7a1b824b75ba779579a7409940",
      "a2bfc588c0544d9cb23631c348f94f5d",
      "bf36ee0a95854c749ae9ccf5d422069c",
      "27c025b864214dd1889de82c9293ec8f",
      "a7e44333fd4643a19c819aefdae8a6eb",
      "b4000ffa90f04b53abfc3ce42e2891d8",
      "e2364db7fc9a44a6994eb614d641d47c",
      "504c36c3163349f59f82f5cbdc14b6be",
      "5a08433916054857bb0cc567fb4c60ca",
      "e34314bdc43b4e69a5b05d66789a0008",
      "8de997606b4c46b79fc1cd53a5ac60ca",
      "c2999810271349ccb416f6531b5a1c0a",
      "fc0ea8c7f2df4fee80208a45f23c9c43",
      "8986129e14ff4baaa49cd82523226f09",
      "10aacc2603394b8185e092c12a3b8ea3",
      "080f09d9d60c4da8858f2786df3810d3",
      "93d299271269463488618d40c738f902",
      "e69fd6e34ec04fdf9c242a8106d130f6",
      "0194e26c69c240699431677e7d59b2c5",
      "b291cb6171034a839ef9a68d6767d298",
      "3b1931e6888f422e88fcad29604da741",
      "5a775ddbe8fd42cb85d37824d76e1fa7",
      "6f17c94f72844cfdadcd321a984fd009",
      "3fd3e6ac47dd468d86dd7b2ddb80593a",
      "e17021ff517747339893636f48a1d509",
      "ad36a562adb94a5ba4a81a9f15f374b4",
      "4d9458c980f14f85a608df1c86ef7841",
      "1d3892112c1c468b97e3cae82d90ff75",
      "ae45a7816bb8432ea81b144d3958a7f9",
      "6077dbcfff754e00ba9e8bb42924e678",
      "7947d54c10954fd8a2cb6dc7baf21127"
     ]
    },
    "id": "cddRdfMjyR8a",
    "outputId": "228735b8-e360-4869-9b88-bc2ef0fe1b68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc07e364b2dd47368b7c5763686af4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa59f667aec04669b8be523defc1be22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25f942219874531b18bdf96145e7c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744687a04db84f57945617adc02b903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66f76085eb846f785a5585de34cd344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680d1ae1700d44d2bf92338873d9a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debdda67208c43c4be8aa327777cbf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee94082cbe9f47f2ba98cadc537889bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce513d953d42768fc7028b54a8d562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818bb765e6cb4934b737dc224764c589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b813fc779ab24c6b9273a14ea1a3936d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34314bdc43b4e69a5b05d66789a0008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1931e6888f422e88fcad29604da741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the imdb dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Reduce dataset size for quicker training\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select(range(2000))\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# Loading the tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Setting format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864,
     "referenced_widgets": [
      "e6dceae04ce74806b14b837fbee17387",
      "a2bcfeb3fa01428493c2b979ec722ba5",
      "d61df66f101c47d6b5e1f09637a15349",
      "d92862fce067473497368fd481d7df5a",
      "c2ebb713c9b74adf807866130882e003",
      "900f3144c5de4870a0c96ecb74a81902",
      "560a76c5d09946f0803d715dd0d1e8b0",
      "10b9d172495d47b9abb7c1c439ebfc58",
      "ef9cf90f03fc449a907ad03289d93593",
      "6d02d92f2e6e438f80b3e7d4951135cf",
      "136db390e4f544239a5b42ae88767f60"
     ]
    },
    "id": "h9ZXR5h7yY6H",
    "outputId": "124e30e7-b633-4c51-a6f8-ad535f6dde94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dceae04ce74806b14b837fbee17387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvRqaWjoyczh",
    "outputId": "ef949aa3-7588-4954-f900-ded9bcd8c7e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "<ipython-input-7-0dcc9421e5a4>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "9s2ErbFcyljX",
    "outputId": "e23fb867-4ed9-4a5b-e240-d633283c8afc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 07:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.280197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.405202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.3047458447217941, metrics={'train_runtime': 457.8516, 'train_samples_per_second': 8.736, 'train_steps_per_second': 1.092, 'total_flos': 1052444221440000.0, 'train_loss': 0.3047458447217941, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIgO0ppd0dPP"
   },
   "outputs": [],
   "source": [
    "# here i have used an example data set\n",
    "movie_data = {\n",
    "    'movie': ['The Matrix', 'Inception', 'The Dark Knight', 'Interstellar', 'Titanic', 'The Godfather'],\n",
    "    'genre': ['Sci-Fi', 'Sci-Fi', 'Action', 'Sci-Fi', 'Romance', 'Crime'],\n",
    "    'description': [\n",
    "        'A computer hacker learns from mysterious rebels about the true nature of his reality and his role in the war against its controllers.',\n",
    "        'A thief who enters the dreams of others to steal secrets from their subconscious is given the inverse task of planting an idea into the mind of a CEO.',\n",
    "        'When the menace known as The Joker emerges from his mysterious past, he wreaks havoc and chaos on the people of Gotham.',\n",
    "        'A team of explorers travel through a wormhole in space in an attempt to ensure humanityâ€™s survival.',\n",
    "        'A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.',\n",
    "        'The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.'\n",
    "    ]\n",
    "}\n",
    "movie_df = pd.DataFrame(movie_data)\n",
    "\n",
    "def recommend_movies(preference):\n",
    "    similar_movies = movie_df[movie_df['genre'].str.contains(preference, case=False)]\n",
    "    return similar_movies[['movie', 'genre', 'description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxNXp1ZK0f9Q",
    "outputId": "6748bfb2-2dda-466e-f8df-8060e5b76d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movie review: the movie killed my time\n",
      "Sentiment of the review: Negative\n"
     ]
    }
   ],
   "source": [
    "# Predicting the sentiment\n",
    "def predict_sentiment(review):\n",
    "    tokens = tokenizer(review, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model(**tokens)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    sentiments = [\"Negative\", \"Positive\"]\n",
    "    return sentiments[prediction]\n",
    "\n",
    "# for user input\n",
    "review = input(\"Enter a movie review: \")\n",
    "sentiment = predict_sentiment(review)\n",
    "print(f\"Sentiment of the review: {sentiment}\")\n",
    "\n",
    "if sentiment == \"Positive\":\n",
    "    genre_preference = input(\"What genre of movies do you prefer? (e.g., Sci-Fi, Action, Romance): \")\n",
    "    suggestions = recommend_movies(genre_preference)\n",
    "    print(\"We recommend these movies based on your preference:\")\n",
    "    print(suggestions)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
